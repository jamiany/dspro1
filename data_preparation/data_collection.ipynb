{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T16:57:46.002114Z",
     "start_time": "2024-12-15T16:57:41.322258Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x8/bv52m_c16jlg9mzb2wmzrjbh0000gn/T/ipykernel_3810/1461776945.py:32: DtypeWarning: Columns (19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(full_path)\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "\n",
    "# kaggle urls / names from used datasets\n",
    "urls = [\n",
    "    \"joebeachcapital/30000-spotify-songs\",\n",
    "    \"tomigelo/spotify-audio-features\",\n",
    "    \"imuhammad/audio-features-and-lyrics-of-spotify-songs\",\n",
    "    \"maharshipandya/-spotify-tracks-dataset\",\n",
    "    \"amitanshjoshi/spotify-1million-tracks\",\n",
    "    \"mrmorj/dataset-of-songs-in-spotify\",\n",
    "    \"thedevastator/spotify-tracks-genre-dataset\",\n",
    "]\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "for idx, url in enumerate(urls):\n",
    "    # download dataset from kaggle\n",
    "    local_path = kagglehub.dataset_download(url)\n",
    "\n",
    "    files = os.listdir(local_path)\n",
    "\n",
    "    csv_files = [file for file in files if file.endswith('.csv')]\n",
    "    \n",
    "    # read all csv files downloaded from kaggle and collect them in one dataframe\n",
    "    df = None\n",
    "    for csv in csv_files:\n",
    "        full_path = os.path.join(local_path, csv)\n",
    "        \n",
    "        df2 = pd.read_csv(full_path)\n",
    "        if df is None:\n",
    "            df = df2\n",
    "        else:\n",
    "            df = pd.concat([df, df2], axis=0)\n",
    "\n",
    "    # store the concatenated dataframe\n",
    "    dataframes.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72d84d243e1cccec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T16:57:46.006812Z",
     "start_time": "2024-12-15T16:57:46.003308Z"
    }
   },
   "outputs": [],
   "source": [
    "# column names of our target dataset\n",
    "columns = ['id', 'name', 'artist', 'album', 'release_date', 'acousticness', 'danceability', 'energy', 'instrumentalness', 'loudness', 'speechiness', 'tempo', 'valence']\n",
    "\n",
    "# the column names of the datasets in the same order as the target column names to allow easy mapping\n",
    "dataset_column_names = [\n",
    "    ['track_id', 'track_name', 'track_artist', 'track_album_name', 'track_album_release_date', 'acousticness', 'danceability', 'energy', 'instrumentalness', 'loudness', 'speechiness', 'tempo', 'valence'],\n",
    "    ['track_id', 'track_name', 'artist_name', None, None, 'acousticness', 'danceability', 'energy', 'instrumentalness', 'loudness', 'speechiness', 'tempo', 'valence'],\n",
    "    ['track_id', 'track_name', 'track_artist', 'track_album_name', 'track_album_release_date', 'acousticness', 'danceability', 'energy', 'instrumentalness', 'loudness', 'speechiness', 'tempo', 'valence'],\n",
    "    ['track_id', 'track_name', 'artists', 'album_name', None, 'acousticness', 'danceability', 'energy', 'instrumentalness', 'loudness', 'speechiness', 'tempo', 'valence'],\n",
    "    ['track_id', 'track_name', 'artist_name', None, 'year', 'acousticness', 'danceability', 'energy', 'instrumentalness', 'loudness', 'speechiness', 'tempo', 'valence'],\n",
    "    ['id', 'song_name', None, None, None, 'acousticness', 'danceability', 'energy', 'instrumentalness', 'loudness', 'speechiness', 'tempo', 'valence'],\n",
    "    ['track_id', 'track_name', 'artists', 'album_name', None, 'acousticness', 'danceability', 'energy', 'instrumentalness', 'loudness', 'speechiness', 'tempo', 'valence'],\n",
    "]\n",
    "\n",
    "# prioritize datasets with more columns available\n",
    "order = [0, 2, 3, 6, 4, 1, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fe02647180166e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T16:57:46.009531Z",
     "start_time": "2024-12-15T16:57:46.007438Z"
    }
   },
   "outputs": [],
   "source": [
    "# transform the dataset_column_names to a mapping dict that pandas can use to rename all columns\n",
    "column_mappings = []\n",
    "\n",
    "for column_names in dataset_column_names:\n",
    "    mapping = {}\n",
    "\n",
    "    for idx, column_name in enumerate(column_names):\n",
    "        if column_name is None:\n",
    "            continue\n",
    "\n",
    "        mapping[column_name] = columns[idx]\n",
    "    \n",
    "    column_mappings.append(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5eafe489bd6ae723",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T16:57:46.706121Z",
     "start_time": "2024-12-15T16:57:46.010175Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing dataset 0\n",
      "appended song data\n",
      "processing dataset 2\n",
      "no new song data\n",
      "appended song data\n",
      "processing dataset 3\n",
      "appended song data\n",
      "processing dataset 6\n",
      "no new song data\n",
      "appended song data\n",
      "processing dataset 4\n",
      "appended song data\n",
      "processing dataset 1\n",
      "appended song data\n",
      "processing dataset 5\n",
      "appended song data\n"
     ]
    }
   ],
   "source": [
    "# initialize an empty dataframe to collect all the data from the different sets\n",
    "df_complete = pd.DataFrame(data=[], columns=columns)\n",
    "id_cache = []\n",
    "\n",
    "# collect the data from each dataset in the specified order\n",
    "for idx in order:\n",
    "    print(f'processing dataset {idx}')\n",
    "\n",
    "    df = dataframes[idx]\n",
    "    mapping = column_mappings[idx]\n",
    "    \n",
    "    # rename the columns to the shared target name\n",
    "    df_temp = df.rename(columns=mapping)\n",
    "    mapped_columns = list(mapping.values())\n",
    "    \n",
    "    # remove all additional columns that the dataset may contain\n",
    "    df_subset = df_temp[mapped_columns]\n",
    "    \n",
    "    # remove all duplicates from the dataset\n",
    "    df_subset = df_subset.drop_duplicates(subset=['id'])\n",
    "    \n",
    "    # remove all rows which were already provided by an earlier dataset\n",
    "    df_cleaned = df_subset[~df_subset['id'].isin(id_cache)]\n",
    "\n",
    "    # skip datasets with no new songs remaining\n",
    "    if len(df_cleaned) == 0:\n",
    "        print('no new song data')\n",
    "\n",
    "    # concatenate the new dataset to the complete dataset\n",
    "    id_cache.extend(df_cleaned['id'].tolist())\n",
    "    if not df_complete.empty:\n",
    "        df_complete = pd.concat([df_complete, df_cleaned], ignore_index=True)\n",
    "    else:\n",
    "        df_complete = df_cleaned\n",
    "    \n",
    "    print('appended song data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8b6b9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['acousticness', 'danceability', 'energy', 'instrumentalness', 'loudness', 'speechiness', 'tempo', 'valence']\n",
    "scaler = StandardScaler()\n",
    "df_complete[features] = scaler.fit_transform(df_complete[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "687f5fa142102aa8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T16:57:51.230251Z",
     "start_time": "2024-12-15T16:57:46.707384Z"
    }
   },
   "outputs": [],
   "source": [
    "# store the complete dataset locally so that the data collection process only needs to run once\n",
    "df_complete.to_csv(path_or_buf='data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd7f7f060794a2d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T16:57:51.232381Z",
     "start_time": "2024-12-15T16:57:51.230992Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
